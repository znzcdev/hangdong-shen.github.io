---
layout:     post
title:      "tools"
subtitle:   " \"linux tools \""
date:       2017-11-27 16:27:45 
author:     "Hangdong"
header-img: "img/post-sample-image.jpg"
catalog: true
tags:
    - 工作总结
---

# 前言 #
自我开始接触脚本语言开始，就发现很多可以重复的工作都可以通过工具的方式来精简。往大的方向看，人工智能的兴起逐渐就会替代低智的工作。我所做的工具有Linux下的，也有Windows下的，前者下的主要基于Python脚本和Java，后者主要基于C++/C#。本篇主要理下Linux的自动化工具。

---

# 正文 #
## 日志 ##
我工作中有大一部分需要对客户的日志进行分析，而用户的日志存在基于Web的数据库当中，这个数据库服务器位于中国大陆之外，通常一个日志文件在300M左右，下载到本地需要20分钟左右的时间，本地在中国大陆。在这种情况下可以考虑这样的一个配置
![](/img/in-post/post-tools/log.png)

配置一个中间主机log tool，这个中间主机通过对Web页面上的信息先进行处理，通过对存储log的主机上的已有日志文件（或者没有）进行读取分析，然后根据前面两者的分析结果来选择下载哪些日志文件，并在下载完成后通知用户。这样不仅能够减少冗余的数据传输，也能释放人力出来做其他事情。

log tool对页面的分析结果，可以用于自动化分析日志使用，根据问题主题和描述中的关键词，问题提出的时间，问题发送的模块，自动把日志里面的数据进行规整和提取。这部分可以采用关键日志存储到数据库系统中，然后赋予权重。

同时基于前面的分析，可以在已有的数据库里面查询是否存在类似的问题，这样可以非常快速得到一些类似的解决方案。这里可以把已有的问题逐步建立到数据库中，原有的数据库是基于MySQL的数据库，无法做到对数据智能分析，这时候可以考虑在建立数据库的时候进行前面所述的权重，然后根据权重排序。也可以采用elasticsearch的全文本检索数据库（相似度算法）来实现。当数据库逐渐充实的时候，就能体现出那种方式是更有效的。

开源的日志解决方案如logstat也是可以参考的，暂时没有研究。

---


